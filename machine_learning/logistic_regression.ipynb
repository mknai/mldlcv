{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(h, y):\n",
    "    return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression using scikit-learn : Digits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Digits Dataset\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Data Shape (1797, 64)\n",
      "Label Data Shape (1797,)\n"
     ]
    }
   ],
   "source": [
    "# Print to show there are 1797 images (8 by 8 images for a dimensionality of 64)\n",
    "print(\"Image Data Shape\" , digits.data.shape)\n",
    "# Print to show there are 1797 labels (integers from 0â€“9)\n",
    "print(\"Label Data Shape\", digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Showing the Images and the Labels (Digits Dataset)\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,4))\n",
    "for index, (image, label) in enumerate(zip(digits.data[0:5], digits.target[0:5])):\n",
    "    plt.subplot(1, 5, index + 1)\n",
    "    plt.imshow(np.reshape(image, (8,8)), cmap=plt.cm.gray)\n",
    "    plt.title('Training: %i\\n' % label, fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data into Training and Test Sets (Digits Dataset)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model creation and training\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# all parameters not specified are set to their defaults\n",
    "logisticRegr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Returns a NumPy Array\n",
    "# Predict for One Observation (image)\n",
    "logisticRegr.predict(x_test[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 8, 2, 6, 6, 7, 1, 9, 8, 5])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict for Multiple Observations (images) at Once\n",
    "logisticRegr.predict(x_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on entire test data\n",
    "predictions = logisticRegr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "# Measuring Model Performance (Digits Dataset)\n",
    "score = logisticRegr.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 39  0  0  0  0  2  0  2  0]\n",
      " [ 0  0 41  3  0  0  0  0  0  0]\n",
      " [ 0  0  1 43  0  0  0  0  0  1]\n",
      " [ 0  0  0  0 38  0  0  0  0  0]\n",
      " [ 0  1  0  0  0 47  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 52  0  0  0]\n",
      " [ 0  1  0  1  1  0  0 45  0  0]\n",
      " [ 0  3  1  0  0  0  0  0 43  1]\n",
      " [ 0  0  0  1  0  1  0  0  1 44]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix (Digits Dataset)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression using scikit-learn : diabetes dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Description : https://www.kaggle.com/uciml/pima-indians-diabetes-database\n",
    "dataset=pd.read_csv(\"data/pima-indians-diabetes-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_pregnant</th>\n",
       "      <th>plasma_glucose</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_pregnant  plasma_glucose  blood_pressure  skin_thickness  insulin  \\\n",
       "0             6             148              72              35        0   \n",
       "1             1              85              66              29        0   \n",
       "2             8             183              64               0        0   \n",
       "3             1              89              66              23       94   \n",
       "4             0             137              40              35      168   \n",
       "\n",
       "    bmi  pedigree  age  diabetes  \n",
       "0  33.6     0.627   50         1  \n",
       "1  26.6     0.351   31         0  \n",
       "2  23.3     0.672   32         1  \n",
       "3  28.1     0.167   21         0  \n",
       "4  43.1     2.288   33         1  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()\n",
    "# dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_pregnant</th>\n",
       "      <th>plasma_glucose</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_pregnant  plasma_glucose  blood_pressure  skin_thickness  \\\n",
       "count    768.000000      768.000000      768.000000      768.000000   \n",
       "mean       3.845052      120.894531       69.105469       20.536458   \n",
       "std        3.369578       31.972618       19.355807       15.952218   \n",
       "min        0.000000        0.000000        0.000000        0.000000   \n",
       "25%        1.000000       99.000000       62.000000        0.000000   \n",
       "50%        3.000000      117.000000       72.000000       23.000000   \n",
       "75%        6.000000      140.250000       80.000000       32.000000   \n",
       "max       17.000000      199.000000      122.000000       99.000000   \n",
       "\n",
       "          insulin         bmi    pedigree         age    diabetes  \n",
       "count  768.000000  768.000000  768.000000  768.000000  768.000000  \n",
       "mean    79.799479   31.992578    0.471876   33.240885    0.348958  \n",
       "std    115.244002    7.884160    0.331329   11.760232    0.476951  \n",
       "min      0.000000    0.000000    0.078000   21.000000    0.000000  \n",
       "25%      0.000000   27.300000    0.243750   24.000000    0.000000  \n",
       "50%     30.500000   32.000000    0.372500   29.000000    0.000000  \n",
       "75%    127.250000   36.600000    0.626250   41.000000    1.000000  \n",
       "max    846.000000   67.100000    2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64      7\n",
       "float64    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: diabetes, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['diabetes'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing value Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following columns have an invalid zero minimum value:\n",
    "\n",
    "* Plasma glucose concentration\n",
    "* Diastolic blood pressure\n",
    "* Triceps skinfold thickness\n",
    "* 2-Hour serum insulin\n",
    "* Body mass index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_pregnant</th>\n",
       "      <th>plasma_glucose</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>139</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>166</td>\n",
       "      <td>72</td>\n",
       "      <td>19</td>\n",
       "      <td>175</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>84</td>\n",
       "      <td>47</td>\n",
       "      <td>230</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>83</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_pregnant  plasma_glucose  blood_pressure  skin_thickness  insulin  \\\n",
       "0              6             148              72              35        0   \n",
       "1              1              85              66              29        0   \n",
       "2              8             183              64               0        0   \n",
       "3              1              89              66              23       94   \n",
       "4              0             137              40              35      168   \n",
       "5              5             116              74               0        0   \n",
       "6              3              78              50              32       88   \n",
       "7             10             115               0               0        0   \n",
       "8              2             197              70              45      543   \n",
       "9              8             125              96               0        0   \n",
       "10             4             110              92               0        0   \n",
       "11            10             168              74               0        0   \n",
       "12            10             139              80               0        0   \n",
       "13             1             189              60              23      846   \n",
       "14             5             166              72              19      175   \n",
       "15             7             100               0               0        0   \n",
       "16             0             118              84              47      230   \n",
       "17             7             107              74               0        0   \n",
       "18             1             103              30              38       83   \n",
       "19             1             115              70              30       96   \n",
       "\n",
       "     bmi  pedigree  age  diabetes  \n",
       "0   33.6     0.627   50         1  \n",
       "1   26.6     0.351   31         0  \n",
       "2   23.3     0.672   32         1  \n",
       "3   28.1     0.167   21         0  \n",
       "4   43.1     2.288   33         1  \n",
       "5   25.6     0.201   30         0  \n",
       "6   31.0     0.248   26         1  \n",
       "7   35.3     0.134   29         0  \n",
       "8   30.5     0.158   53         1  \n",
       "9    0.0     0.232   54         1  \n",
       "10  37.6     0.191   30         0  \n",
       "11  38.0     0.537   34         1  \n",
       "12  27.1     1.441   57         0  \n",
       "13  30.1     0.398   59         1  \n",
       "14  25.8     0.587   51         1  \n",
       "15  30.0     0.484   32         1  \n",
       "16  45.8     0.551   31         1  \n",
       "17  29.6     0.254   31         1  \n",
       "18  43.3     0.183   33         0  \n",
       "19  34.6     0.529   32         1  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets cross check\n",
    "dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"data/pima-indians-diabetes-data.csv\", header=None, skiprows=1)\n",
    "print((dataset[[1,2,3,4,5]] == 0.0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1   2   3    4     5      6   7  8\n",
       "0  6  148  72  35    0  33.6  0.627  50  1\n",
       "1  1   85  66  29    0  26.6  0.351  31  0\n",
       "2  8  183  64   0    0  23.3  0.672  32  1\n",
       "3  1   89  66  23   94  28.1  0.167  21  0\n",
       "4  0  137  40  35  168  43.1  2.288  33  1"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "6      0\n",
      "7      0\n",
      "8      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Mark zero values as missing or NaN\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, np.NaN)\n",
    "# Count the number of NaN values in each column\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1     2     3      4     5      6   7  8\n",
       "0  6  148.0  72.0  35.0    NaN  33.6  0.627  50  1\n",
       "1  1   85.0  66.0  29.0    NaN  26.6  0.351  31  0\n",
       "2  8  183.0  64.0   NaN    NaN  23.3  0.672  32  1\n",
       "3  1   89.0  66.0  23.0   94.0  28.1  0.167  21  0\n",
       "4  0  137.0  40.0  35.0  168.0  43.1  2.288  33  1"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values with mean column values\n",
    "dataset.fillna(dataset.mean(), inplace=True)\n",
    "# Count the number of NaN values in each column\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.columns[i], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into inputs and outputs\n",
    "values = dataset.values\n",
    "X = values[:,0:8]\n",
    "y = values[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have created the Logistic Regression model with some random hyperparameter values. The hyperparameters that you used are:\n",
    "\n",
    "penalty : Used to specify the norm used in the penalization (regularization).\n",
    "dual : Dual or primal formulation. The dual formulation is only implemented for l2 penalty with liblinear solver. Prefer dual=False when n_samples > n_features.\n",
    "max_iter : Maximum number of iterations taken to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l1',dual=False,max_iter=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=110,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7747395833333334"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will need the following dependencies for applying Cross-validation and evaluating the cross-validated score\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the k-fold cross-validator\n",
    "\n",
    "kfold = KFold(n_splits=3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "result = cross_val_score(lr, X, y, cv=kfold, scoring='accuracy')\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual=[True,False]\n",
    "max_iter=[100,110,120,130,140]\n",
    "param_grid = dict(dual=dual,max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.752604 using {'dual': False, 'max_iter': 100}\n",
      "Execution time: 5.540132999420166 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "lr = LogisticRegression(penalty='l2')\n",
    "grid = GridSearchCV(estimator=lr, param_grid=param_grid, cv = 3, n_jobs=-1)\n",
    "\n",
    "start_time = time.time()\n",
    "grid_result = grid.fit(X, y)\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.763021 using {'C': 2.0, 'dual': False, 'max_iter': 100}\n",
      "Execution time: 0.23415184020996094 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "dual=[True,False]\n",
    "max_iter=[100,110,120,130,140]\n",
    "C = [1.0,1.5,2.0,2.5]\n",
    "param_grid = dict(dual=dual,max_iter=max_iter,C=C)\n",
    "\n",
    "lr = LogisticRegression(penalty='l2')\n",
    "grid = GridSearchCV(estimator=lr, param_grid=param_grid, cv = 3, n_jobs=-1)\n",
    "\n",
    "start_time = time.time()\n",
    "grid_result = grid.fit(X, y)\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.756510 using {'max_iter': 100, 'dual': False, 'C': 1.5}\n",
      "Execution time: 0.1636359691619873 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random = RandomizedSearchCV(estimator=lr, param_distributions=param_grid, cv = 3, n_jobs=-1)\n",
    "\n",
    "start_time = time.time()\n",
    "random_result = random.fit(X, y)\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['diabetes'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-bc17dfdc0a90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#create a dataframe with all training data except the target column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'diabetes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#check that the target variable has been removed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4095\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4096\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4097\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4098\u001b[0m         )\n\u001b[1;32m   4099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3913\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3914\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3915\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3945\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3946\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3947\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3948\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5333\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not found in axis\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5334\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5335\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['diabetes'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#create a dataframe with all training data except the target column\n",
    "X = dataset.drop(columns=['diabetes'])\n",
    "\n",
    "#check that the target variable has been removed\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encode target column\n",
    "Y = pd.get_dummies(dataset.diabetes, drop_first=True)\n",
    "\n",
    "# Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data in training set  576 576\n",
      "Number of data in tesing set  192 192\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of data in training set \",len(trainX), len(trainY))\n",
    "print(\"Number of data in tesing set \",len(testX), len(testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7447916666666666"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are three steps to model something with sklearn\n",
    "# 1. Set up the model\n",
    "model = LogisticRegression()\n",
    "# 2. Use fit\n",
    "model.fit(trainX, trainY)\n",
    "# 3. Check the score\n",
    "model.score(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_pregnant</th>\n",
       "      <th>plasma_glucose</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>6</td>\n",
       "      <td>98</td>\n",
       "      <td>58</td>\n",
       "      <td>33</td>\n",
       "      <td>190</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.430</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>75</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>35.7</td>\n",
       "      <td>0.148</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.158</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>8</td>\n",
       "      <td>107</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0.856</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>7</td>\n",
       "      <td>136</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.9</td>\n",
       "      <td>0.210</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>6</td>\n",
       "      <td>103</td>\n",
       "      <td>72</td>\n",
       "      <td>32</td>\n",
       "      <td>190</td>\n",
       "      <td>37.7</td>\n",
       "      <td>0.324</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>48</td>\n",
       "      <td>18</td>\n",
       "      <td>76</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0.323</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.8</td>\n",
       "      <td>0.932</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>4</td>\n",
       "      <td>154</td>\n",
       "      <td>72</td>\n",
       "      <td>29</td>\n",
       "      <td>126</td>\n",
       "      <td>31.3</td>\n",
       "      <td>0.338</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>5</td>\n",
       "      <td>147</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.7</td>\n",
       "      <td>0.218</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>10</td>\n",
       "      <td>111</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.141</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>7</td>\n",
       "      <td>179</td>\n",
       "      <td>95</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>34.2</td>\n",
       "      <td>0.164</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>4</td>\n",
       "      <td>148</td>\n",
       "      <td>60</td>\n",
       "      <td>27</td>\n",
       "      <td>318</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.150</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "      <td>74</td>\n",
       "      <td>18</td>\n",
       "      <td>67</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.997</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>167</td>\n",
       "      <td>33.3</td>\n",
       "      <td>0.962</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "      <td>72</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>37.2</td>\n",
       "      <td>0.267</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>5</td>\n",
       "      <td>86</td>\n",
       "      <td>68</td>\n",
       "      <td>28</td>\n",
       "      <td>71</td>\n",
       "      <td>30.2</td>\n",
       "      <td>0.364</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>4</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.212</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>65</td>\n",
       "      <td>26</td>\n",
       "      <td>130</td>\n",
       "      <td>42.6</td>\n",
       "      <td>0.431</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>5</td>\n",
       "      <td>104</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.8</td>\n",
       "      <td>0.153</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>78</td>\n",
       "      <td>29</td>\n",
       "      <td>76</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.365</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>13</td>\n",
       "      <td>106</td>\n",
       "      <td>72</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.178</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>64</td>\n",
       "      <td>27</td>\n",
       "      <td>87</td>\n",
       "      <td>33.2</td>\n",
       "      <td>0.289</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>10</td>\n",
       "      <td>129</td>\n",
       "      <td>76</td>\n",
       "      <td>28</td>\n",
       "      <td>122</td>\n",
       "      <td>35.9</td>\n",
       "      <td>0.280</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>7</td>\n",
       "      <td>184</td>\n",
       "      <td>84</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.355</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>6</td>\n",
       "      <td>109</td>\n",
       "      <td>60</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.206</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>74</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.149</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>86</td>\n",
       "      <td>36</td>\n",
       "      <td>120</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0.127</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>3</td>\n",
       "      <td>89</td>\n",
       "      <td>74</td>\n",
       "      <td>16</td>\n",
       "      <td>85</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.551</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>60</td>\n",
       "      <td>46</td>\n",
       "      <td>178</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.415</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0.258</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>60</td>\n",
       "      <td>37</td>\n",
       "      <td>75</td>\n",
       "      <td>37.2</td>\n",
       "      <td>0.509</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.6</td>\n",
       "      <td>0.479</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>74</td>\n",
       "      <td>19</td>\n",
       "      <td>53</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.229</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>4</td>\n",
       "      <td>146</td>\n",
       "      <td>85</td>\n",
       "      <td>27</td>\n",
       "      <td>100</td>\n",
       "      <td>28.9</td>\n",
       "      <td>0.189</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>3</td>\n",
       "      <td>191</td>\n",
       "      <td>68</td>\n",
       "      <td>15</td>\n",
       "      <td>130</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.299</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>9</td>\n",
       "      <td>122</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>1.114</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>7</td>\n",
       "      <td>159</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>0.294</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>66</td>\n",
       "      <td>20</td>\n",
       "      <td>90</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.867</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>4</td>\n",
       "      <td>123</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.226</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "      <td>100</td>\n",
       "      <td>35</td>\n",
       "      <td>240</td>\n",
       "      <td>57.3</td>\n",
       "      <td>0.880</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>84</td>\n",
       "      <td>44</td>\n",
       "      <td>545</td>\n",
       "      <td>38.7</td>\n",
       "      <td>0.619</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>86</td>\n",
       "      <td>17</td>\n",
       "      <td>105</td>\n",
       "      <td>29.3</td>\n",
       "      <td>0.695</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>140</td>\n",
       "      <td>33.8</td>\n",
       "      <td>0.088</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>33</td>\n",
       "      <td>105</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>6</td>\n",
       "      <td>104</td>\n",
       "      <td>74</td>\n",
       "      <td>18</td>\n",
       "      <td>156</td>\n",
       "      <td>29.9</td>\n",
       "      <td>0.722</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.743</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13</td>\n",
       "      <td>145</td>\n",
       "      <td>82</td>\n",
       "      <td>19</td>\n",
       "      <td>110</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>82</td>\n",
       "      <td>39</td>\n",
       "      <td>272</td>\n",
       "      <td>41.5</td>\n",
       "      <td>0.270</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.7</td>\n",
       "      <td>0.190</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>94</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>49.3</td>\n",
       "      <td>0.358</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>182</td>\n",
       "      <td>43.3</td>\n",
       "      <td>1.224</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>26</td>\n",
       "      <td>50</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.597</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>11</td>\n",
       "      <td>60</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.527</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>64</td>\n",
       "      <td>23</td>\n",
       "      <td>115</td>\n",
       "      <td>36.9</td>\n",
       "      <td>0.471</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>6</td>\n",
       "      <td>194</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0.129</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>6</td>\n",
       "      <td>123</td>\n",
       "      <td>72</td>\n",
       "      <td>45</td>\n",
       "      <td>230</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.733</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>3</td>\n",
       "      <td>106</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.207</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_pregnant  plasma_glucose  blood_pressure  skin_thickness  insulin  \\\n",
       "668             6              98              58              33      190   \n",
       "324             2             112              75              32        0   \n",
       "624             2             108              64               0        0   \n",
       "690             8             107              80               0        0   \n",
       "473             7             136              90               0        0   \n",
       "..            ...             ...             ...             ...      ...   \n",
       "554             1              84              64              23      115   \n",
       "319             6             194              78               0        0   \n",
       "594             6             123              72              45      230   \n",
       "6               3              78              50              32       88   \n",
       "615             3             106              72               0        0   \n",
       "\n",
       "      bmi  pedigree  age  \n",
       "668  34.0     0.430   43  \n",
       "324  35.7     0.148   21  \n",
       "624  30.8     0.158   21  \n",
       "690  24.6     0.856   34  \n",
       "473  29.9     0.210   50  \n",
       "..    ...       ...  ...  \n",
       "554  36.9     0.471   28  \n",
       "319  23.5     0.129   59  \n",
       "594  33.6     0.733   34  \n",
       "6    31.0     0.248   26  \n",
       "615  25.8     0.207   27  \n",
       "\n",
       "[192 rows x 8 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load the model / Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'logr_model'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=uint8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xnew = [[6, 98, 58, 33, 190, 34.0, 0.430, 43]]\n",
    "ynew = model.predict(Xnew)\n",
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=uint8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynew = loaded_model.predict(Xnew)\n",
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
