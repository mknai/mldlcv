{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(h, y):\n",
    "    return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression using scikit-learn : Digits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Digits Dataset\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Data Shape (1797, 64)\n",
      "Label Data Shape (1797,)\n"
     ]
    }
   ],
   "source": [
    "# Print to show there are 1797 images (8 by 8 images for a dimensionality of 64)\n",
    "print(\"Image Data Shape\" , digits.data.shape)\n",
    "# Print to show there are 1797 labels (integers from 0â€“9)\n",
    "print(\"Label Data Shape\", digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHsAAAEKCAYAAACCF1ktAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3X+0pXddH/r3xwxUBZoZrYIm6BARrNe7HMyUlsLCgKRFS016e+HirSyCbYPe2pus2mp0rV5i21XDrWhYt63NFGVSpbUdxMSLKGaWSam/KAkOrRBAmBtL0iKyyAQEhQV+7x97Tzs5npmz98z+nud7nnm91jprn7P3cz7PZ++Z98w+n/N9nqdaawEAAABgHj5v6gYAAAAA2BzDHgAAAIAZMewBAAAAmBHDHgAAAIAZMewBAAAAmBHDHgAAAIAZMewZQFU9vqpaVb15A7Xurarf30RfcLGTTRiPXMKYZBPGJJsXr4t62LP8S7/Ox3VT9zxHtXB9Vd1XVZ+sqlNVdbyqrp66N6Yhm9OrqqdU1d+vqp+pqpNnvNZPmro3piGX06uqq6rqNcs32x+tqk9X1Qer6l9U1VdO3R/TkM3pVdULquoNVfXuqvpYVf3hMptvqqrnTt0f05DN8VTV46rqA8vX+71T99PbvqkbmNgPbnPfjUkuTfLaJKe2PHaiUx+fTPKnk2xiSvpXk/yJDdTZTT+W5JVJHkjyL5I8LslLk/xSVb2itXZ0utaYiGxO79lJ/kGSluQDST6R5AmTdsTU5HJ6b86i319N8pNJ/ijJc7L4P/SlVfW81tpvTtgf05DN6b0wyXOTvD3J8SR/kORgkr+c5K9U1U2ttVdP1x4Tkc3x/EiSJ07dxG6p1trUPQylqh5I8pVJntJae2DabuZvuXrnl5K8O8mzWmufWN7/9CT3JqkkT22tfXi6LhmBbO6uqjqY5LIk72qt/X5V3ZvkyiRfJo+cJpe7q6p+IMnrWmsf2XL/P07y/Ul+o7X2rEmaYyiyubuq6vNba3+4zf1XJLkvi19kfmlrbesP91xkZHM6VfUtSX4+yXdlsdjgfa21r5m2q74u6sO4ztfpYxWr6guq6h8tl4J9pqr+6fLxL66qm6rq31fVf10+9rvLwyGu3KbetsdRVtUPL+8/XFV/bXmY0x8sl27/ZFV96dl623Lfi5Z1/m5VPbOq3lpVH18+h+Pb9bT8vq+oqp9a7u9Ty/3/b2fWu7BXMskibEnyg6cHPUnSWntfkn+ZxX+OL9vAfrgIyObmstlae6C19qutNcdlc0HkcqO5/MdbBz1L/zDJ55L8uar6/AvdDxcH2dxoNv/YoGd5/8ksfnn5mCx+wIcdyeZGf9Y8va8vTvLjSe5I8lObqjs6w57z93lZLKe+Lsm/T3JrkvuXjz0ji2V7f5jkziyWi92T5FuS/Fqtf+zu92Yx+Hh/kn+W5LeTfHuSt1bVJWvUeU6St2VxWMaRLFbUPD/JPbXlWP+qujzJryf5a1ksKXxtFqtvbk/y17crfkYw1zn51/OW/bx1m8d+YXn7/DXqgWxucZ7ZhE2Syy02nMvPZXFI1+kPWJVsbrHJbFbVZVm8jp9M8sELrcdFRTa3uMBs3pbF0PU7z+N796yL/Zw9F+ILsjh/xddtsyTznUme1Fp7+Mw7q+qrsjiW9zVJ/swa+/qmJIdaa+9f1qksppLfmuQvJnnLinWuSfLi1tobz+jpe5L8cJK/lUXQT3tNki9P8n+11v7hGdv/8yS/skbvZ1VVT0yyP8mHW2sf32aT317ePm0T++OiIZswHrns62VZvIk93lr7zC7sj/mQzQ2qqj+f5C9kkccnZ/HcvjDJ37RSljXJ5oZU1cuyONfQS1trv1tVj99k/ZFZ2XNhvn+7Y29bax/bGr7l/R9M8nNJDlfVF62xn39yOnzLOi3J65ZfPnONOm89M3xLR7bWqaonJPlfknwkyT85c+PW2m8kOXaW+ndncfKvVSemly5vHznL46fv379iPThNNh9t3WxCD3L5aBvJZVV9TRZvpD+d5O9dSC0uWrL5aBeSzT+f5FVJfiCLIewfJfnfW2u3n0ctkM1HWzubVfXkJP9PkmOttX+76vfNhWHPhfmPZ3ugqp5Xi8stPrg8jrJVVUvyiuUml62xn3u3ue9Dy9sDF1JneZ6cR7bU+bosVn3dd5ZjkLedtrbWPtlae29r7cE1eoIeZPPRtWSTEcjlo2tdcC6Xh4i8JYtfnryytdbrSi7Mm2w+utZ5Z7O19sOttcpiNc//nOTfJTlWVa9ZtxZENrfWWiubyxVKR7P4Zcj/scr3zI3DuM7fp848ofCZqurbk/yrLC5vd1eS/y+LY3VbFks7n5X1Llm33Zn7P7u8Xec4yrNdAeCzW+qcXnHzu2fZ/mz3r+v0yp1Lz/L46ftduYB1yCaMRy43bDnouSeLk75eb+UA50k2O2it/UGS30rynctDRv5OVd3VWvvFXvtkdmTzwn1XFucM+quttY9uqOaeYthz/s51zfp/lOQTSZ6xPAv/f1dVX51FAEd2+vw5TzzL42e7fy3LYyZPJXliVf3Jbc7b89XL2/cHViebMB653KCq+ookv5zkKUm+w6CHCyCb/f1CFiehvSqJYQ+rks0L9w3L259ZLPL5Y56+XA2VJI9prX12u432MsOeDauqfVn8lu1t24TvMRk/fEnyn7OYwF5ZVZ+/zfK652xwX3cn+StZnPxr6/GZ37y8/eUN7o+LlGzCeORyfVV1RRb/L16e5OWttYvmErLsHtncqNOH08zuB0l2n2yu5T+c5f59SV6exVEmp88xNMsrWTpnz4YtJ4IPJfmfqupPnb6/qj4vyQ9l8Vu4oS2XDN6R5Euz5WSPVfVnk7x4u++rqsdV1dcsL6W3qh9b3r5qebKu07WenuRvZLEk8SfXqAfbks21swndyeV6uayqp2ZxCd7Lsjjpq0EPXcjm2tnc9iS2VfWnk/zd5Zc/v2o9OBvZXD2brbXbW2t/Y+tHku9ebvLhM+6f5bDHyp4+fjSLK2P8p6p6UxaTwm9McjCLpZzffPZvHcb3ZDFV/QdV9dwk78jit4gvSfL/Jrk2f3wC+rzlYz+f5EWr7KS1dldVHUlyff7H6/W4JC/N4nKD39Fa+/CFPx1IIpsrZ7Oq/kSS28646+Dy9rVV9QfLz/9pa227k/rBOuRyhVxW1WOzGPR8eZJfT/K1VXXzNpseaa391/N7GvAosrni/5lJfrWqfjvJu5I8mOSxSZ6W5OoszlXyQ621X7+wpwL/nWyuns2LmmFPHz+SxQmzvjvJd2SxOuWeLP7y/s3sgQC21v5LVf25LCbEfzGLML4niyVvX5BFALeeY+d8fWeS+5a335XFsr53JLmltXbXhvYBiWyu4zHLmlu95IzP35ztr+AA65DL1Tw2i0FPslimf7al+m9OYtjDJsjm6n4gixPBPjvJlySpJB/O4hCR21prd29gH3CabLKSau1c536CP66qXpvk/0zynNbar07dD7AgmzAeuYQxySaMSTY3x7CHs6qqL9+6FLyq/kyStyX5WJKvnONZy2F0sgnjkUsYk2zCmGSzP4dxcS73V9U7k7w7yR8meXr+x7LAvyV8MBnZhPHIJYxJNmFMstmZlT2cVVX9UJJvSfIVSR6f5OEkv5bk/26t/dqUvcHFTDZhPHIJY5JNGJNs9mfYAwAAADAjnzd1AwAAAABsjmEPAAAAwIwY9gAAAADMiGEPAAAAwIwY9gAAAADMiGEPAAAAwIwY9gAAAADMiGEPAAAAwIwY9gAAAADMiGEPAAAAwIwY9gAAAADMiGEPAAAAwIwY9gAAAADMiGEPAAAAwIwY9gAAAADMiGEPAAAAwIwY9gAAAADMiGEPAAAAwIwY9gAAAADMiGEPAAAAwIwY9gAAAADMiGEPAAAAwIzs61G0qlqPurvlwIEDXetfdtllXet//OMf71o/SR566KGu9T/3uc91rd9ba62m7mGrvZ7L3p72tKd1rb9vX5d/bh+ldy4feeSRrvV3wUdba18ydRNbyea5Pf7xj+9a/6lPfWrX+knyqU99qmv997///V3r7wLZ7OBJT3pS1/q9389++tOf7lo/Se6///6u9ff6+9nI5p50ySWXdK1/8ODBrvWT5IMf/GD3fexxK2Wz/08fe9ALXvCCrvVvueWWrvWPHz/etX6S3HTTTV3rP/zww13rw1ZHjhzpWn///v1d6yfJq171qq7177zzzq71d8HvTN0A6zt8+HDX+nfccUfX+kly4sSJrvWvuuqqrvV3gWx28PKXv7xr/d7vZ0+ePNm1ftL/35cZvJ+VzT3oCU94Qtf6r3nNa7rWT5Jrr722+z72uJWy6TAuAAAAgBkx7AEAAACYEcMeAAAAgBkx7AEAAACYEcMeAAAAgBkx7AEAAACYEcMeAAAAgBlZadhTVS+sqvdV1Qeq6qbeTQGrkU0Yk2zCmGQTxiSbsHk7Dnuq6pIk/yzJNyf52iTfVlVf27sx4NxkE8YkmzAm2YQxySb0scrKnmcm+UBr7WRr7TNJfjrJNX3bAlYgmzAm2YQxySaMSTahg1WGPZcl+dAZXz+4vO9Rqur6qrq3qu7dVHPAOe2YTbmEScgmjEk2YUyyCR3s21Sh1tqRJEeSpKrapuoC508uYUyyCWOSTRiTbML6VlnZ81CSJ5/x9eXL+4BpySaMSTZhTLIJY5JN6GCVYc87knx1VT2lqh6b5KVJfq5vW8AKZBPGJJswJtmEMckmdLDjYVyttc9W1XcneWuSS5L8RGvt3d07A85JNmFMsgljkk0Yk2xCHyuds6e19pYkb+ncC7Am2YQxySaMSTZhTLIJm7fKYVwAAAAA7BGGPQAAAAAzYtgDAAAAMCOGPQAAAAAzYtgDAAAAMCOGPQAAAAAzstKl1y82t9xyS9f6V1xxRdf6Bw4c6Fo/ST72sY91rf+Sl7yka/1jx451rc/ec+rUqa71v/Ebv7Fr/SR53vOe17X+nXfe2bU+e9OhQ4e61r/77ru71n/kkUe61k+SgwcPdt8He0/v95svfvGLu9Z/5Stf2bX+bbfd1rV+klx55ZVd6x8/frxrfdjOdddd17X+iRMnutZnc6zsAQAAAJgRwx4AAACAGTHsAQAAAJgRwx4AAACAGTHsAQAAAJgRwx4AAACAGTHsAQAAAJgRwx4AAACAGdlx2FNVP1FVH6mq39qNhoDVyCaMSTZhTLIJY5JN6GOVlT1Hk7ywcx/A+o5GNmFERyObMKKjkU0Y0dHIJmzcjsOe1trbknxsF3oB1iCbMCbZhDHJJoxJNqGPfZsqVFXXJ7l+U/WACyeXMCbZhDHJJoxJNmF9Gxv2tNaOJDmSJFXVNlUXOH9yCWOSTRiTbMKYZBPW52pcAAAAADNi2AMAAAAwI6tcev3fJPn1JE+vqger6q/3bwvYiWzCmGQTxiSbMCbZhD52PGdPa+3bdqMRYD2yCWOSTRiTbMKYZBP6cBgXAAAAwIwY9gAAAADMiGEPAAAAwIwY9gAAAADMiGEPAAAAwIwY9gAAAADMyI6XXh/RlVde2bX+FVdc0bX+V33VV3Wtf/Lkya71k+Suu+7qWr/3n/GxY8e61mfzDh061LX+VVdd1bX+bjhx4sTULXARuvbaa7vWf9e73tW1/h133NG1fpK86lWv6r4P9p4jR450rf/qV7+6a/177723a/3deD97/Pjx7vuArfbv39+1/nXXXde1/q233tq1fpIcPHiw+z56euCBB6ZuIYmVPQAAAACzYtgDAAAAMCOGPQAAAAAzYtgDAAAAMCOGPQAAAAAzYtgDAAAAMCOGPQAAAAAzYtgDAAAAMCM7Dnuq6slVdXdVvaeq3l1VN+xGY8C5ySaMSTZhTLIJY5JN6GPfCtt8Nsn3tNbeWVVPSHJfVd3VWntP596Ac5NNGJNswphkE8Ykm9DBjit7Wmv/rbX2zuXnn0hyf5LLejcGnJtswphkE8YkmzAm2YQ+1jpnT1UdTPKMJG/v0QxwfmQTxiSbMCbZhDHJJmzOKodxJUmq6vFJfibJja21j2/z+PVJrt9gb8AKzpVNuYTpyCaMSTZhTLIJm7XSsKeqHpNF8N7QWnvTdtu01o4kObLcvm2sQ+CsdsqmXMI0ZBPGJJswJtmEzVvlalyV5MeT3N9a+5H+LQGrkE0Yk2zCmGQTxiSb0Mcq5+x5dpKXJXl+VZ1YfnxL576AnckmjEk2YUyyCWOSTehgx8O4Wmu/kqR2oRdgDbIJY5JNGJNswphkE/pY62pcAAAAAIzNsAcAAABgRgx7AAAAAGbEsAcAAABgRgx7AAAAAGbEsAcAAABgRna89PqIDhw40LX+fffd17X+yZMnu9bfDb1fI/aeG2+8sWv9m2++uWv9Sy+9tGv93XDPPfdM3QIXoVtvvbVr/QceeKBr/d79J8mdd97ZfR/sPb3fD15xxRV7uv7x48e71k/6/0zx8MMPd63P3nTdddd1rX/w4MGu9Y8ePdq1ftL//+ZTp051rd/755ZVWdkDAAAAMCOGPQAAAAAzYtgDAAAAMCOGPQAAAAAzYtgDAAAAMCOGPQAAAAAzYtgDAAAAMCOGPQAAAAAzsuOwp6o+v6r+Y1W9q6reXVU/uBuNAecmmzAm2YQxySaMSTahj30rbPPpJM9vrf1+VT0mya9U1S+01n6jc2/AuckmjEk2YUyyCWOSTehgx2FPa60l+f3ll49ZfrSeTQE7k00Yk2zCmGQTxiSb0MdK5+ypqkuq6kSSjyS5q7X29r5tAauQTRiTbMKYZBPGJJuweSsNe1prn2utHUpyeZJnVtXXbd2mqq6vqnur6t5NNwlsb6dsyiVMQzZhTLIJY5JN2Ly1rsbVWjuV5O4kL9zmsSOttcOttcObag5YzdmyKZcwLdmEMckmjEk2YXNWuRrXl1TV/uXnX5Dk6iTv7d0YcG6yCWOSTRiTbMKYZBP6WOVqXF+W5PaquiSL4dC/a629uW9bwApkE8YkmzAm2YQxySZ0sMrVuP5TkmfsQi/AGmQTxiSbMCbZhDHJJvSx1jl7AAAAABibYQ8AAADAjBj2AAAAAMyIYQ8AAADAjBj2AAAAAMyIYQ8AAADAjOx46fURHThwoGv948ePd60/B73/DB5++OGu9dm8W2+9tWv9o0ePdq0/h79z+/fvn7oFBtT778WNN97Ytf61117btf5uuO6666ZugYvQyZMnu9b/oi/6oq7177rrrq71d2MfV199ddf6c3jvMqJrrrmma/0f/dEf7Vr/9ttv71p/N9xwww1d67/iFa/oWn8UVvYAAAAAzIhhDwAAAMCMGPYAAAAAzIhhDwAAAMCMGPYAAAAAzIhhDwAAAMCMGPYAAAAAzIhhDwAAAMCMrDzsqapLquo3q+rNPRsC1iObMCbZhPHIJYxJNmHz1lnZc0OS+3s1Apw32YQxySaMRy5hTLIJG7bSsKeqLk/yl5K8rm87wDpkE8YkmzAeuYQxySb0serKnluTfG+SP+rYC7A+2YQxySaMRy5hTLIJHew47KmqFyX5SGvtvh22u76q7q2qezfWHXBWq2RTLmH3ySaMx/tZGJNsQj+rrOx5dpJvraoHkvx0kudX1U9t3ai1dqS1dri1dnjDPQLb2zGbcgmTkE0Yj/ezMCbZhE52HPa01r6/tXZ5a+1gkpcm+eXW2rd37ww4J9mEMckmjEcuYUyyCf2sczUuAAAAAAa3b52NW2v3JLmnSyfAeZNNGJNswnjkEsYkm7BZVvYAAAAAzIhhDwAAAMCMGPYAAAAAzIhhDwAAAMCMGPYAAAAAzIhhDwAAAMCMGPYAAAAAzMi+qRs4Hw8//HDX+ldeeWXX+r0dOHCg+z56v0bHjh3rWh/m6NChQ13rnzhxomt9+rj55pu71r/hhhu61u/t2muv7b6PU6dOdd8H7Lbe78evvvrqrvWT5Lbbbuta//u+7/u61r/pppu61r9YPfLII3u6/stf/vKu9Xu/39wNd9xxx9Qt7AorewAAAABmxLAHAAAAYEYMewAAAABmxLAHAAAAYEYMewAAAABmxLAHAAAAYEYMewAAAABmZN8qG1XVA0k+keRzST7bWjvcsylgNbIJY5JNGJNswphkEzZvpWHP0vNaax/t1glwvmQTxiSbMCbZhDHJJmyQw7gAAAAAZmTVYU9L8ktVdV9VXd+zIWAtsgljkk0Yk2zCmGQTNmzVw7ie01p7qKq+NMldVfXe1trbztxgGUrBhN11zmzKJUxGNmFMsgljkk3YsJVW9rTWHlrefiTJzyZ55jbbHGmtHXYyLdg9O2VTLmEasgljkk0Yk2zC5u047Kmqx1XVE05/nuQvJPmt3o0B5yabMCbZhDHJJoxJNqGPVQ7jemKSn62q09v/69baL3btCliFbMKYZBPGJJswJtmEDnYc9rTWTib5+l3oBViDbMKYZBPGJJswJtmEPlx6HQAAAGBGDHsAAAAAZsSwBwAAAGBGDHsAAAAAZsSwBwAAAGBGDHsAAAAAZsSwBwAAAGBG9k3dwPk4efJk1/pXXnll1/ovfvGL93T93fDqV7966hYAZuHo0aNd61911VVd63/913991/p33HFH1/pJcuedd3at//rXv75r/d7908ctt9zStf7x48e71j9w4EDX+knyghe8oGv9Y8eOda1PH/fcc0/X+vv37+9a/9ChQ13r9359kuT222/vWv/UqVNd64/Cyh4AAACAGTHsAQAAAJgRwx4AAACAGTHsAQAAAJgRwx4AAACAGTHsAQAAAJgRwx4AAACAGTHsAQAAAJiRlYY9VbW/qt5YVe+tqvur6lm9GwN2JpswJtmEMckmjEk2YfP2rbjda5P8Ymvtf62qxyb5wo49AauTTRiTbMKYZBPGJJuwYTsOe6rq0iTPTXJdkrTWPpPkM33bAnYimzAm2YQxySaMSTahj1UO43pKkt9L8vqq+s2qel1VPW7rRlV1fVXdW1X3brxLYDs7ZlMuYRKyCWOSTRiTbEIHqwx79iX5hiQ/1lp7RpJPJrlp60attSOttcOttcMb7hHY3o7ZlEuYhGzCmGQTxiSb0MEqw54HkzzYWnv78us3ZhFGYFqyCWOSTRiTbMKYZBM62HHY01r7cJIPVdXTl3d9U5L3dO0K2JFswphkE8YkmzAm2YQ+Vr0a199O8oblmdFPJnlFv5aANcgmjEk2YUyyCWOSTdiwlYY9rbUTSRwfCYORTRiTbMKYZBPGJJuweaucswcAAACAPcKwBwAAAGBGDHsAAAAAZsSwBwAAAGBGDHsAAAAAZsSwBwAAAGBGVrr0+mhOnjzZtf5NN93Utf4tt9zStf59993XtX6SHD7syojsrlOnTnWtf+edd3atf80113StnyRXXXVV1/pHjx7tWp8+Tpw40bX+oUOH9nT9m2++uWv9pH/+H3jgga71e//7SB8PP/xw1/q33XZb1/q74dixY13rv/KVr+xaH7bT+z3zpZde2rV+4j3npljZAwAAADAjhj0AAAAAM2LYAwAAADAjhj0AAAAAM2LYAwAAADAjhj0AAAAAM2LYAwAAADAjhj0AAAAAM7LjsKeqnl5VJ874+HhV3bgbzQFnJ5swJtmEMckmjEk2oY99O23QWntfkkNJUlWXJHkoyc927gvYgWzCmGQTxiSbMCbZhD7WPYzrm5J8sLX2Oz2aAc6bbMKYZBPGJJswJtmEDdlxZc8WL03yb7Z7oKquT3L9BXcEnI9tsymXMDnZhDHJJoxJNmFDVl7ZU1WPTfKtSY5t93hr7Uhr7XBr7fCmmgN2dq5syiVMRzZhTLIJY5JN2Kx1DuP65iTvbK39bq9mgPMimzAm2YQxySaMSTZhg9YZ9nxbznIIFzAp2YQxySaMSTZhTLIJG7TSsKeqHpfk6iRv6tsOsA7ZhDHJJoxJNmFMsgmbt9IJmltrn0zyxZ17AdYkmzAm2YQxySaMSTZh89a99DoAAAAAAzPsAQAAAJgRwx4AAACAGTHsAQAAAJgRwx4AAACAGTHsAQAAAJiRaq1tvmjV7yX5nTW+5U8l+ejGG9k9+p/WaP1/ZWvtS6ZuYquLMJfJ3n8O+t8s2RzDXu8/2fvPYbT+ZXMM+p/eaM9BNseg/2mN2P9K2ewy7FlXVd3bWjs8dR/nS//T2uv9j2oOr+tefw76Zzt7/XXd6/0ne/857PX+R7XXX1f9T28Oz2FEe/111f+09nL/DuMCAAAAmBHDHgAAAIAZGWXYc2TqBi6Q/qe11/sf1Rxe173+HPTPdvb667rX+0/2/nPY6/2Paq+/rvqf3hyew4j2+uuq/2nt2f6HOGcPAAAAAJsxysoeAAAAADbAsAcAAABgRiYd9lTVC6vqfVX1gaq6acpe1lVVT66qu6vqPVX17qq6YeqezkdVXVJVv1lVb566l3VV1f6qemNVvbeq7q+qZ03d01zI5vRkk+3I5vRkk+3I5vRkk+3I5vRkczqTnbOnqi5J8v4kVyd5MMk7knxba+09kzS0pqr6siRf1lp7Z1U9Icl9Sa7dK/2fVlV/J8nhJH+ytfaiqftZR1XdnuQ/tNZeV1WPTfKFrbVTU/e118nmGGSTrWRzDLLJVrI5BtlkK9kcg2xOZ8qVPc9M8oHW2snW2meS/HSSaybsZy2ttf/WWnvn8vNPJLk/yWXTdrWeqro8yV9K8rqpe1lXVV2a5LlJfjxJWmuf2UvBG5xsTkw2OQvZnJhschayOTHZ5Cxkc2KyOa0phz2XJfnQGV8/mD32l/e0qjqY5BlJ3j5tJ2u7Ncn3JvmjqRs5D09J8ntJXr9cFvi6qnrc1E3NhGxOTzbZjmxOTzbZjmxOTzbZjmxOTzYn5ATNF6iqHp/kZ5Lc2Fr7+NT9rKqqXpTkI621+6bu5TztS/INSX6stfaMJJ9MsqeOw6Uv2ZyMbHJOsjkZ2eScZHMyssk5yeZk9nw2pxz2PJTkyWd8ffnyvj2jqh6TRfDe0Fp709T9rOnZSb61qh7IYknj86vqp6ZtaS0PJnmwtXZ6uv3GLMLIhZPNackmZyOb05JNzkY2pyWbnI1sTks2JzblsOcdSb66qp6yPNnRS5P83IT9rKWqKovj9+5vrf3I1P2sq7X2/a21y1trB7N47X/peD81AAAAzElEQVS5tfbtE7e1stbah5N8qKqevrzrm5LsqZOVDUw2JySbnINsTkg2OQfZnJBscg6yOSHZnN6+qXbcWvtsVX13krcmuSTJT7TW3j1VP+fh2UleluQ/V9WJ5X0/0Fp7y4Q9XWz+dpI3LP/xPpnkFRP3MwuyyQbIZgeyyQbIZgeyyQbIZgeyyQbs6WxOdul1AAAAADbPCZoBAAAAZsSwBwAAAGBGDHsAAAAAZsSwBwAAAGBGDHsAAAAAZsSwBwAAAGBGDHsAAAAAZuT/B7saHoGmAvP2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114e157f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Showing the Images and the Labels (Digits Dataset)\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,4))\n",
    "for index, (image, label) in enumerate(zip(digits.data[0:5], digits.target[0:5])):\n",
    "    plt.subplot(1, 5, index + 1)\n",
    "    plt.imshow(np.reshape(image, (8,8)), cmap=plt.cm.gray)\n",
    "    plt.title('Training: %i\\n' % label, fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data into Training and Test Sets (Digits Dataset)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model creation and training\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# all parameters not specified are set to their defaults\n",
    "logisticRegr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noor-4785/vpython3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/noor-4785/vpython3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Returns a NumPy Array\n",
    "# Predict for One Observation (image)\n",
    "logisticRegr.predict(x_test[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 8, 2, 6, 6, 7, 1, 9, 8, 5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict for Multiple Observations (images) at Once\n",
    "logisticRegr.predict(x_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on entire test data\n",
    "predictions = logisticRegr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "# Measuring Model Performance (Digits Dataset)\n",
    "score = logisticRegr.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 39  0  0  0  0  2  0  2  0]\n",
      " [ 0  0 41  3  0  0  0  0  0  0]\n",
      " [ 0  0  1 43  0  0  0  0  0  1]\n",
      " [ 0  0  0  0 38  0  0  0  0  0]\n",
      " [ 0  1  0  0  0 47  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 52  0  0  0]\n",
      " [ 0  1  0  1  1  0  0 45  0  0]\n",
      " [ 0  3  1  0  0  0  0  0 43  1]\n",
      " [ 0  0  0  1  0  1  0  0  1 44]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix (Digits Dataset)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression using scikit-learn : diabetes dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"data/pima-indians-diabetes-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_pregnant</th>\n",
       "      <th>plasma_glucose</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_pregnant  plasma_glucose  blood_pressure  skin_thickness  insulin  \\\n",
       "0             6             148              72              35        0   \n",
       "1             1              85              66              29        0   \n",
       "2             8             183              64               0        0   \n",
       "3             1              89              66              23       94   \n",
       "4             0             137              40              35      168   \n",
       "\n",
       "    bmi  pedigree  age  diabetes  \n",
       "0  33.6     0.627   50         1  \n",
       "1  26.6     0.351   31         0  \n",
       "2  23.3     0.672   32         1  \n",
       "3  28.1     0.167   21         0  \n",
       "4  43.1     2.288   33         1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_pregnant</th>\n",
       "      <th>plasma_glucose</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_pregnant  plasma_glucose  blood_pressure  skin_thickness  \\\n",
       "count    768.000000      768.000000      768.000000      768.000000   \n",
       "mean       3.845052      120.894531       69.105469       20.536458   \n",
       "std        3.369578       31.972618       19.355807       15.952218   \n",
       "min        0.000000        0.000000        0.000000        0.000000   \n",
       "25%        1.000000       99.000000       62.000000        0.000000   \n",
       "50%        3.000000      117.000000       72.000000       23.000000   \n",
       "75%        6.000000      140.250000       80.000000       32.000000   \n",
       "max       17.000000      199.000000      122.000000       99.000000   \n",
       "\n",
       "          insulin         bmi    pedigree         age    diabetes  \n",
       "count  768.000000  768.000000  768.000000  768.000000  768.000000  \n",
       "mean    79.799479   31.992578    0.471876   33.240885    0.348958  \n",
       "std    115.244002    7.884160    0.331329   11.760232    0.476951  \n",
       "min      0.000000    0.000000    0.078000   21.000000    0.000000  \n",
       "25%      0.000000   27.300000    0.243750   24.000000    0.000000  \n",
       "50%     30.500000   32.000000    0.372500   29.000000    0.000000  \n",
       "75%    127.250000   36.600000    0.626250   41.000000    1.000000  \n",
       "max    846.000000   67.100000    2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_pregnant</th>\n",
       "      <th>plasma_glucose</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_pregnant  plasma_glucose  blood_pressure  skin_thickness  insulin  \\\n",
       "0             6             148              72              35        0   \n",
       "1             1              85              66              29        0   \n",
       "2             8             183              64               0        0   \n",
       "3             1              89              66              23       94   \n",
       "4             0             137              40              35      168   \n",
       "\n",
       "    bmi  pedigree  age  \n",
       "0  33.6     0.627   50  \n",
       "1  26.6     0.351   31  \n",
       "2  23.3     0.672   32  \n",
       "3  28.1     0.167   21  \n",
       "4  43.1     2.288   33  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dataframe with all training data except the target column\n",
    "X = dataset.drop(columns=['diabetes'])\n",
    "\n",
    "#check that the target variable has been removed\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encode target column\n",
    "Y = pd.get_dummies(dataset.diabetes, drop_first=True)\n",
    "\n",
    "# Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data in training set  576 576\n",
      "Number of data in tesing set  192 192\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of data in training set \",len(trainX), len(trainY))\n",
    "print(\"Number of data in tesing set \",len(testX), len(testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noor-4785/vpython3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/noor-4785/vpython3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7447916666666666"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are three steps to model something with sklearn\n",
    "# 1. Set up the model\n",
    "model = LogisticRegression()\n",
    "# 2. Use fit\n",
    "model.fit(trainX, trainY)\n",
    "# 3. Check the score\n",
    "model.score(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_pregnant</th>\n",
       "      <th>plasma_glucose</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>6</td>\n",
       "      <td>98</td>\n",
       "      <td>58</td>\n",
       "      <td>33</td>\n",
       "      <td>190</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.430</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>75</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>35.7</td>\n",
       "      <td>0.148</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.158</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>8</td>\n",
       "      <td>107</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0.856</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>7</td>\n",
       "      <td>136</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.9</td>\n",
       "      <td>0.210</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>6</td>\n",
       "      <td>103</td>\n",
       "      <td>72</td>\n",
       "      <td>32</td>\n",
       "      <td>190</td>\n",
       "      <td>37.7</td>\n",
       "      <td>0.324</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>48</td>\n",
       "      <td>18</td>\n",
       "      <td>76</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0.323</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.8</td>\n",
       "      <td>0.932</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>4</td>\n",
       "      <td>154</td>\n",
       "      <td>72</td>\n",
       "      <td>29</td>\n",
       "      <td>126</td>\n",
       "      <td>31.3</td>\n",
       "      <td>0.338</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>5</td>\n",
       "      <td>147</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.7</td>\n",
       "      <td>0.218</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>10</td>\n",
       "      <td>111</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.141</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>7</td>\n",
       "      <td>179</td>\n",
       "      <td>95</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>34.2</td>\n",
       "      <td>0.164</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>4</td>\n",
       "      <td>148</td>\n",
       "      <td>60</td>\n",
       "      <td>27</td>\n",
       "      <td>318</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.150</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "      <td>74</td>\n",
       "      <td>18</td>\n",
       "      <td>67</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.997</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>167</td>\n",
       "      <td>33.3</td>\n",
       "      <td>0.962</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "      <td>72</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>37.2</td>\n",
       "      <td>0.267</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>5</td>\n",
       "      <td>86</td>\n",
       "      <td>68</td>\n",
       "      <td>28</td>\n",
       "      <td>71</td>\n",
       "      <td>30.2</td>\n",
       "      <td>0.364</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>4</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.212</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>65</td>\n",
       "      <td>26</td>\n",
       "      <td>130</td>\n",
       "      <td>42.6</td>\n",
       "      <td>0.431</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>5</td>\n",
       "      <td>104</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.8</td>\n",
       "      <td>0.153</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>78</td>\n",
       "      <td>29</td>\n",
       "      <td>76</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.365</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>13</td>\n",
       "      <td>106</td>\n",
       "      <td>72</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.178</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>64</td>\n",
       "      <td>27</td>\n",
       "      <td>87</td>\n",
       "      <td>33.2</td>\n",
       "      <td>0.289</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>10</td>\n",
       "      <td>129</td>\n",
       "      <td>76</td>\n",
       "      <td>28</td>\n",
       "      <td>122</td>\n",
       "      <td>35.9</td>\n",
       "      <td>0.280</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>7</td>\n",
       "      <td>184</td>\n",
       "      <td>84</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.355</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>6</td>\n",
       "      <td>109</td>\n",
       "      <td>60</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.206</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>74</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.149</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>86</td>\n",
       "      <td>36</td>\n",
       "      <td>120</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0.127</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>3</td>\n",
       "      <td>89</td>\n",
       "      <td>74</td>\n",
       "      <td>16</td>\n",
       "      <td>85</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.551</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>60</td>\n",
       "      <td>46</td>\n",
       "      <td>178</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.415</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0.258</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>60</td>\n",
       "      <td>37</td>\n",
       "      <td>75</td>\n",
       "      <td>37.2</td>\n",
       "      <td>0.509</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.6</td>\n",
       "      <td>0.479</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>74</td>\n",
       "      <td>19</td>\n",
       "      <td>53</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.229</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>4</td>\n",
       "      <td>146</td>\n",
       "      <td>85</td>\n",
       "      <td>27</td>\n",
       "      <td>100</td>\n",
       "      <td>28.9</td>\n",
       "      <td>0.189</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>3</td>\n",
       "      <td>191</td>\n",
       "      <td>68</td>\n",
       "      <td>15</td>\n",
       "      <td>130</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.299</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>9</td>\n",
       "      <td>122</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>1.114</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>7</td>\n",
       "      <td>159</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>0.294</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>66</td>\n",
       "      <td>20</td>\n",
       "      <td>90</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.867</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>4</td>\n",
       "      <td>123</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.226</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "      <td>100</td>\n",
       "      <td>35</td>\n",
       "      <td>240</td>\n",
       "      <td>57.3</td>\n",
       "      <td>0.880</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "      <td>84</td>\n",
       "      <td>44</td>\n",
       "      <td>545</td>\n",
       "      <td>38.7</td>\n",
       "      <td>0.619</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>86</td>\n",
       "      <td>17</td>\n",
       "      <td>105</td>\n",
       "      <td>29.3</td>\n",
       "      <td>0.695</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>140</td>\n",
       "      <td>33.8</td>\n",
       "      <td>0.088</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>33</td>\n",
       "      <td>105</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>6</td>\n",
       "      <td>104</td>\n",
       "      <td>74</td>\n",
       "      <td>18</td>\n",
       "      <td>156</td>\n",
       "      <td>29.9</td>\n",
       "      <td>0.722</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.743</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13</td>\n",
       "      <td>145</td>\n",
       "      <td>82</td>\n",
       "      <td>19</td>\n",
       "      <td>110</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>82</td>\n",
       "      <td>39</td>\n",
       "      <td>272</td>\n",
       "      <td>41.5</td>\n",
       "      <td>0.270</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.7</td>\n",
       "      <td>0.190</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>94</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>49.3</td>\n",
       "      <td>0.358</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>182</td>\n",
       "      <td>43.3</td>\n",
       "      <td>1.224</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>26</td>\n",
       "      <td>50</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.597</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>11</td>\n",
       "      <td>60</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.527</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>64</td>\n",
       "      <td>23</td>\n",
       "      <td>115</td>\n",
       "      <td>36.9</td>\n",
       "      <td>0.471</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>6</td>\n",
       "      <td>194</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0.129</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>6</td>\n",
       "      <td>123</td>\n",
       "      <td>72</td>\n",
       "      <td>45</td>\n",
       "      <td>230</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.733</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>3</td>\n",
       "      <td>106</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.207</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_pregnant  plasma_glucose  blood_pressure  skin_thickness  insulin  \\\n",
       "668             6              98              58              33      190   \n",
       "324             2             112              75              32        0   \n",
       "624             2             108              64               0        0   \n",
       "690             8             107              80               0        0   \n",
       "473             7             136              90               0        0   \n",
       "204             6             103              72              32      190   \n",
       "97              1              71              48              18       76   \n",
       "336             0             117               0               0        0   \n",
       "568             4             154              72              29      126   \n",
       "148             5             147              78               0        0   \n",
       "667            10             111              70              27        0   \n",
       "212             7             179              95              31        0   \n",
       "199             4             148              60              27      318   \n",
       "265             5              96              74              18       67   \n",
       "760             2              88              58              26       16   \n",
       "356             1             125              50              40      167   \n",
       "501             3              84              72              32        0   \n",
       "457             5              86              68              28       71   \n",
       "604             4             183               0               0        0   \n",
       "213             0             140              65              26      130   \n",
       "636             5             104              74               0        0   \n",
       "544             1              88              78              29       76   \n",
       "86             13             106              72              54        0   \n",
       "208             1              96              64              27       87   \n",
       "281            10             129              76              28      122   \n",
       "209             7             184              84              33        0   \n",
       "581             6             109              60              27        0   \n",
       "639             1             100              74              12       46   \n",
       "328             2             102              86              36      120   \n",
       "431             3              89              74              16       85   \n",
       "..            ...             ...             ...             ...      ...   \n",
       "718             1             108              60              46      178   \n",
       "90              1              80              55               0        0   \n",
       "377             1              87              60              37       75   \n",
       "235             4             171              72               0        0   \n",
       "158             2              88              74              19       53   \n",
       "69              4             146              85              27      100   \n",
       "260             3             191              68              15      130   \n",
       "131             9             122              56               0        0   \n",
       "44              7             159              64               0        0   \n",
       "70              2             100              66              20       90   \n",
       "264             4             123              62               0        0   \n",
       "673             3             123             100              35      240   \n",
       "286             5             155              84              44      545   \n",
       "640             0             102              86              17      105   \n",
       "135             2             125              60              20      140   \n",
       "745            12             100              84              33      105   \n",
       "165             6             104              74              18      156   \n",
       "164             0             131              88               0        0   \n",
       "28             13             145              82              19      110   \n",
       "608             0             152              82              39      272   \n",
       "583             8             100              76               0        0   \n",
       "746             1             147              94              41        0   \n",
       "292             2             128              78              37      182   \n",
       "136             0             100              70              26       50   \n",
       "432             1              80              74              11       60   \n",
       "554             1              84              64              23      115   \n",
       "319             6             194              78               0        0   \n",
       "594             6             123              72              45      230   \n",
       "6               3              78              50              32       88   \n",
       "615             3             106              72               0        0   \n",
       "\n",
       "      bmi  pedigree  age  \n",
       "668  34.0     0.430   43  \n",
       "324  35.7     0.148   21  \n",
       "624  30.8     0.158   21  \n",
       "690  24.6     0.856   34  \n",
       "473  29.9     0.210   50  \n",
       "204  37.7     0.324   55  \n",
       "97   20.4     0.323   22  \n",
       "336  33.8     0.932   44  \n",
       "568  31.3     0.338   37  \n",
       "148  33.7     0.218   65  \n",
       "667  27.5     0.141   40  \n",
       "212  34.2     0.164   60  \n",
       "199  30.9     0.150   29  \n",
       "265  33.6     0.997   43  \n",
       "760  28.4     0.766   22  \n",
       "356  33.3     0.962   28  \n",
       "501  37.2     0.267   28  \n",
       "457  30.2     0.364   24  \n",
       "604  28.4     0.212   36  \n",
       "213  42.6     0.431   24  \n",
       "636  28.8     0.153   48  \n",
       "544  32.0     0.365   29  \n",
       "86   36.6     0.178   45  \n",
       "208  33.2     0.289   21  \n",
       "281  35.9     0.280   39  \n",
       "209  35.5     0.355   41  \n",
       "581  25.0     0.206   27  \n",
       "639  19.5     0.149   28  \n",
       "328  45.5     0.127   23  \n",
       "431  30.4     0.551   38  \n",
       "..    ...       ...  ...  \n",
       "718  35.5     0.415   24  \n",
       "90   19.1     0.258   21  \n",
       "377  37.2     0.509   22  \n",
       "235  43.6     0.479   26  \n",
       "158  29.0     0.229   22  \n",
       "69   28.9     0.189   27  \n",
       "260  30.9     0.299   34  \n",
       "131  33.3     1.114   33  \n",
       "44   27.4     0.294   40  \n",
       "70   32.9     0.867   28  \n",
       "264  32.0     0.226   35  \n",
       "673  57.3     0.880   22  \n",
       "286  38.7     0.619   34  \n",
       "640  29.3     0.695   27  \n",
       "135  33.8     0.088   31  \n",
       "745  30.0     0.488   46  \n",
       "165  29.9     0.722   41  \n",
       "164  31.6     0.743   32  \n",
       "28   22.2     0.245   57  \n",
       "608  41.5     0.270   27  \n",
       "583  38.7     0.190   42  \n",
       "746  49.3     0.358   27  \n",
       "292  43.3     1.224   31  \n",
       "136  30.8     0.597   21  \n",
       "432  30.0     0.527   22  \n",
       "554  36.9     0.471   28  \n",
       "319  23.5     0.129   59  \n",
       "594  33.6     0.733   34  \n",
       "6    31.0     0.248   26  \n",
       "615  25.8     0.207   27  \n",
       "\n",
       "[192 rows x 8 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load the model / Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'logr_model'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=uint8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xnew = [[6, 98, 58, 33, 190, 34.0, 0.430, 43]]\n",
    "ynew = model.predict(Xnew)\n",
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=uint8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynew = loaded_model.predict(Xnew)\n",
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
