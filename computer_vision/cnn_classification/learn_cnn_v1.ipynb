{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and loading necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python\n",
    "# ! pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/noor-4785/Documents/training_and_developement/vit_fdp/temp_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "\n",
    "from imutils import paths\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from keras import applications\n",
    "from keras.applications.vgg16 import VGG16\n",
    "# from keras.applications.vgg19 import VGG19\n",
    "# from keras.applications.resnet50 import ResNet50\n",
    "# from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, precision_recall_fscore_support, average_precision_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/foldername"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset path\n",
    "\n",
    "# path = 'data/cat_and_dog_100'\n",
    "path = 'data/cat_and_dog_1000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise required variables\n",
    "data = []\n",
    "labels = []\n",
    "features = []\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise required hyperparameters\n",
    "IMAGE_DIM = 48\n",
    "TEST_SPLIT = 0.20\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "INIT_LR = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class information :  {'cat': 0, 'dog': 1}\n"
     ]
    }
   ],
   "source": [
    "# Extracting the class information from the given folder : Class name and corresponding number of files\n",
    "class_dir_paths = os.listdir(path)\n",
    "class_dict = {}\n",
    "idx = 0\n",
    "\n",
    "for class_dir_path in class_dir_paths:\n",
    "    if (os.path.isdir(os.path.join(path, class_dir_path))):\n",
    "        class_name = class_dir_path\n",
    "        class_dict[class_name] = idx\n",
    "        idx += 1\n",
    "\n",
    "print(\"Class information : \", class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the image paths and randomly shuffle them\n",
    "imagePaths = sorted(list(paths.list_images(path)))\n",
    "random.seed(RANDOM_STATE)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/cat_and_dog_1000/cat/cat.813.jpg'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagePaths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images readed,  2001\n",
      "Total number of labels extracted,  2001\n"
     ]
    }
   ],
   "source": [
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (IMAGE_DIM, IMAGE_DIM))\n",
    "    image = img_to_array(image)\n",
    "    feature = image_to_feature_vector(image)\n",
    "    data.append(image)\n",
    "    features.append(feature)\n",
    "\n",
    "    # extract the class label from the image path and update the\n",
    "    # labels list\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(class_dict[label])\n",
    "\n",
    "print(\"Total number of images readed, \", len(data))\n",
    "print(\"Total number of labels extracted, \", len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image in training set  1600 1600\n",
      "Number of image in tesing set  401 401\n"
     ]
    }
   ],
   "source": [
    "features = np.array(features, dtype=\"float\") / 255.0\n",
    "\n",
    "(ttrainX, ttestX, ttrainY, ttestY) = train_test_split(\n",
    "    features, labels, test_size=TEST_SPLIT, random_state=RANDOM_STATE)\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "ttrainY = to_categorical(ttrainY, num_classes=len(class_dict))\n",
    "ttestY = to_categorical(ttestY, num_classes=len(class_dict))\n",
    "\n",
    "print(\"Number of image in training set \", len(ttrainX), len(ttrainY))\n",
    "print(\"Number of image in tesing set \", len(ttestX), len(ttestY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the architecture of the network\n",
    "model = Sequential()\n",
    "model.add(Dense(768, input_dim=3072, activation=\"relu\"))\n",
    "model.add(Dense(384, activation=\"relu\"))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 768)               2360064   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 384)               295296    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 770       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 2,656,130\n",
      "Trainable params: 2,656,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "sgd = SGD(lr=0.01)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Train on 1600 samples, validate on 401 samples\n",
      "Epoch 1/5\n",
      "1600/1600 [==============================] - 1s 805us/step - loss: 0.7250 - acc: 0.5206 - val_loss: 0.6955 - val_acc: 0.5037\n",
      "Epoch 2/5\n",
      "1600/1600 [==============================] - 1s 545us/step - loss: 0.6889 - acc: 0.5613 - val_loss: 0.6543 - val_acc: 0.6185\n",
      "Epoch 3/5\n",
      "1600/1600 [==============================] - 1s 567us/step - loss: 0.6649 - acc: 0.6038 - val_loss: 0.6766 - val_acc: 0.5511\n",
      "Epoch 4/5\n",
      "1600/1600 [==============================] - 1s 582us/step - loss: 0.6540 - acc: 0.6125 - val_loss: 0.6405 - val_acc: 0.6758\n",
      "Epoch 5/5\n",
      "1600/1600 [==============================] - 1s 601us/step - loss: 0.6380 - acc: 0.6500 - val_loss: 0.6360 - val_acc: 0.6608\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training network...\")\n",
    "nn_history = model.fit(\n",
    "    ttrainX,\n",
    "    ttrainY,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    validation_data=(ttestX, ttestY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 0s 107us/step\n",
      "401/401 [==============================] - 0s 104us/step\n",
      "************ Training Metrics ************\n",
      "Accuracy =  0.704375\n",
      "Confusion Matrix\n",
      "[[543 243]\n",
      " [230 584]]\n",
      "************ Testing Metrics ************\n",
      "Accuracy =  0.660847880893812\n",
      "Confusion Matrix\n",
      "[[140  75]\n",
      " [ 61 125]]\n"
     ]
    }
   ],
   "source": [
    "print_score(model, ttrainX, ttrainY, ttestX, ttestY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_save_metrics(nn_history, 'nn_plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image in training set  1600 1600\n",
      "Number of image in tesing set  401 401\n"
     ]
    }
   ],
   "source": [
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=TEST_SPLIT, random_state=RANDOM_STATE)\n",
    "\n",
    "print(\"Number of image in training set \", len(trainX), len(trainY))\n",
    "print(\"Number of image in tesing set \", len(testX), len(testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels from integers to vectors\n",
    "trainY = to_categorical(trainY, num_classes=len(class_dict))\n",
    "testY = to_categorical(testY, num_classes=len(class_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_net(width, height, depth, classes):\n",
    "\n",
    "    finalAct = \"softmax\" if classes > 2 else \"sigmoid\"\n",
    "\n",
    "    # initialize the model\n",
    "    model = Sequential()\n",
    "    inputShape = (height, width, depth)\n",
    "\n",
    "    # if we are using \"channels first\", update the input shape\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        inputShape = (depth, height, width)\n",
    "\n",
    "    # first set of CONV => RELU => POOL layers\n",
    "    model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=inputShape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # second set of CONV => RELU => POOL layers\n",
    "    model.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # first (and only) set of FC => RELU layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    # softmax classifier\n",
    "    model.add(Dense(classes))\n",
    "    model.add(Activation(finalAct))\n",
    "\n",
    "    # return the constructed network architecture\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simple_net(IMAGE_DIM, IMAGE_DIM, 3, len(class_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the optimizer\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "\n",
    "# Complile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 6s 115ms/step - loss: 0.7178 - acc: 0.5081 - val_loss: 0.6885 - val_acc: 0.5661\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 0.6920 - acc: 0.5247 - val_loss: 0.6881 - val_acc: 0.5599\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.6837 - acc: 0.5837 - val_loss: 0.6694 - val_acc: 0.5636\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 5s 90ms/step - loss: 0.6755 - acc: 0.5722 - val_loss: 0.6688 - val_acc: 0.5586\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 5s 90ms/step - loss: 0.6643 - acc: 0.6038 - val_loss: 0.6301 - val_acc: 0.6858\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 0.6348 - acc: 0.6594 - val_loss: 0.5796 - val_acc: 0.7419\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.6270 - acc: 0.6466 - val_loss: 0.5813 - val_acc: 0.7120\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.6195 - acc: 0.6700 - val_loss: 0.6144 - val_acc: 0.6421\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.6158 - acc: 0.6547 - val_loss: 0.6019 - val_acc: 0.6783\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 0.5974 - acc: 0.6850 - val_loss: 0.5570 - val_acc: 0.7269\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 0.6004 - acc: 0.6784 - val_loss: 0.5785 - val_acc: 0.7282\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.5917 - acc: 0.6881 - val_loss: 0.5806 - val_acc: 0.6995\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 0.5853 - acc: 0.7053 - val_loss: 0.5456 - val_acc: 0.7469\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 4s 90ms/step - loss: 0.5910 - acc: 0.6903 - val_loss: 0.5559 - val_acc: 0.7569\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 5s 96ms/step - loss: 0.5806 - acc: 0.6956 - val_loss: 0.5619 - val_acc: 0.7207\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.5543 - acc: 0.7206 - val_loss: 0.5225 - val_acc: 0.7681\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.5555 - acc: 0.7188 - val_loss: 0.5558 - val_acc: 0.7207\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.5595 - acc: 0.7188 - val_loss: 0.6294 - val_acc: 0.6584\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.5705 - acc: 0.7078 - val_loss: 0.5378 - val_acc: 0.7382\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 0.5462 - acc: 0.7212 - val_loss: 0.5471 - val_acc: 0.7145\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 5s 97ms/step - loss: 0.5510 - acc: 0.7153 - val_loss: 0.5435 - val_acc: 0.7369\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 0.5480 - acc: 0.7209 - val_loss: 0.5666 - val_acc: 0.7145\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 0.5206 - acc: 0.7428 - val_loss: 0.5291 - val_acc: 0.7257\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.5258 - acc: 0.7463 - val_loss: 0.5200 - val_acc: 0.7444\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 0.5316 - acc: 0.7297 - val_loss: 0.4909 - val_acc: 0.7855\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training network...\")\n",
    "H = model.fit_generator(\n",
    "    aug.flow(trainX, trainY, batch_size=BATCH_SIZE),\n",
    "    validation_data=(testX, testY),\n",
    "    steps_per_epoch=len(trainX) // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 1s 441us/step\n",
      "401/401 [==============================] - 0s 443us/step\n",
      "************ Training Metrics ************\n",
      "Accuracy =  0.795\n",
      "Confusion Matrix\n",
      "[[645 141]\n",
      " [190 624]]\n",
      "************ Testing Metrics ************\n",
      "Accuracy =  0.7855361590064375\n",
      "Confusion Matrix\n",
      "[[176  39]\n",
      " [ 47 139]]\n"
     ]
    }
   ],
   "source": [
    "print_score(model,trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('keras_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the saved model and do prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading network...\n"
     ]
    }
   ],
   "source": [
    "# load the image\n",
    "image = cv2.imread('data/cat_and_dog_1000/cat/cat.813.jpg')\n",
    "orig = image.copy()\n",
    "\n",
    "# pre-process the image for classification\n",
    "image = cv2.resize(image, (IMAGE_DIM, IMAGE_DIM))\n",
    "image = image.astype(\"float\") / 255.0\n",
    "image = img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)\n",
    "\n",
    "# load the trained convolutional neural network\n",
    "print(\"[INFO] loading network...\")\n",
    "model = load_model('keras_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cat, dog) = model.predict(image)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4179721, 0.5898914)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One with the highest value is our prediction\n",
    "(cat, dog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(IMAGE_DIM, IMAGE_DIM, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 48, 48, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze all the layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building model based on Function API\n",
    "X = base_model.output\n",
    "X = Flatten()(X)  \n",
    "\n",
    "#Adding last FC layers based on hyperparams given\n",
    "\n",
    "X = Dense(128, activation='relu')(X)\n",
    "X = Dense(128, activation='relu')(X)\n",
    "\n",
    "# for layer_param in hyperparameters['top_layers']:\n",
    "# \tX = self.layers[layer_param[0]](layer_param[1], activation=layer_param[2])(X)\n",
    "\n",
    "#Adding dropout\n",
    "X = Dropout(0.5)(X)\n",
    "\n",
    "#Adding the last layer for prediction\n",
    "predictions = Dense(2, activation='sigmoid')(X)\n",
    "\n",
    "#creating the final model\n",
    "model = Model(base_model.input, predictions)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 48, 48, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 14,797,122\n",
      "Trainable params: 82,434\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/5\n",
      "50/50 [==============================] - 12s 231ms/step - loss: 0.6620 - acc: 0.6047 - val_loss: 0.6101 - val_acc: 0.6683\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 11s 228ms/step - loss: 0.5908 - acc: 0.6878 - val_loss: 0.5626 - val_acc: 0.7170\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 12s 231ms/step - loss: 0.5668 - acc: 0.7109 - val_loss: 0.5800 - val_acc: 0.6958\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 12s 237ms/step - loss: 0.5455 - acc: 0.7200 - val_loss: 0.5691 - val_acc: 0.7120\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 12s 241ms/step - loss: 0.5388 - acc: 0.7297 - val_loss: 0.5583 - val_acc: 0.7057\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training network...\")\n",
    "H = model.fit_generator(\n",
    "    aug.flow(trainX, trainY, batch_size=BATCH_SIZE),\n",
    "    validation_data=(testX, testY),\n",
    "    steps_per_epoch=len(trainX) // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 9s 5ms/step\n",
      "401/401 [==============================] - 2s 6ms/step\n",
      "************ Training Metrics ************\n",
      "Accuracy =  0.7909375\n",
      "Confusion Matrix\n",
      "[[622 164]\n",
      " [170 644]]\n",
      "************ Testing Metrics ************\n",
      "Accuracy =  0.7057356602533202\n",
      "Confusion Matrix\n",
      "[[146  69]\n",
      " [ 48 138]]\n"
     ]
    }
   ],
   "source": [
    "print_score(model,trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze only the last few layers\n",
    "N_LAYERS_TO_FREEZE = 15\n",
    "\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in model.layers[15:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "# Unfreeze all the layers\n",
    "# for layer in model.layers:\n",
    "#     layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Finetuning the network...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Finetuning the network...\")\n",
    "model.compile(\n",
    "    optimizer=SGD(lr=0.001, momentum=0.9),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50/50 [==============================] - 21s 425ms/step - loss: 0.5571 - acc: 0.7116 - val_loss: 0.6375 - val_acc: 0.6421\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 20s 407ms/step - loss: 0.4950 - acc: 0.7531 - val_loss: 0.4837 - val_acc: 0.7581\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 21s 412ms/step - loss: 0.5020 - acc: 0.7588 - val_loss: 0.4659 - val_acc: 0.7544\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 21s 411ms/step - loss: 0.4694 - acc: 0.7484 - val_loss: 0.5017 - val_acc: 0.7494\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 21s 417ms/step - loss: 0.4336 - acc: 0.8003 - val_loss: 0.4653 - val_acc: 0.7706\n"
     ]
    }
   ],
   "source": [
    "H_tune = model.fit_generator(\n",
    "    aug.flow(trainX, trainY, batch_size=BATCH_SIZE),\n",
    "    validation_data=(testX, testY),\n",
    "    steps_per_epoch=len(trainX) // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 9s 6ms/step\n",
      "401/401 [==============================] - 2s 6ms/step\n",
      "************ Training Metrics ************\n",
      "Accuracy =  0.8684375\n",
      "Confusion Matrix\n",
      "[[676 110]\n",
      " [ 97 717]]\n",
      "************ Testing Metrics ************\n",
      "Accuracy =  0.770573566233428\n",
      "Confusion Matrix\n",
      "[[155  60]\n",
      " [ 31 155]]\n"
     ]
    }
   ],
   "source": [
    "print_score(model,trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_save_metrics(model_history):\n",
    "\n",
    "    # plot the training loss and accuracy\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    N = EPOCHS\n",
    "    plt.plot(\n",
    "        np.arange(0, N), model_history.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(\n",
    "        np.arange(0, N), model_history.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(np.arange(0, N), model_history.history[\"acc\"], label=\"train_acc\")\n",
    "    plt.plot(\n",
    "        np.arange(0, N), model_history.history[\"val_acc\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(model, trainX, trainY, testX, testY):\n",
    "\n",
    "    train_score = model.evaluate(trainX, trainY)\n",
    "    train_predictions = model.predict(trainX)\n",
    "    train_predictions = np.round(train_predictions)\n",
    "\n",
    "    test_score = model.evaluate(testX, testY)\n",
    "    test_predictions = model.predict(testX)\n",
    "    test_predictions = np.round(test_predictions)\n",
    "\n",
    "    print(\"************ Training Metrics ************\")\n",
    "\n",
    "#     print(\"Loss = \", train_score[0])\n",
    "    print(\"Accuracy = \", train_score[1])\n",
    "#     print(\"classification Report\")\n",
    "#     print(classification_report(trainY, train_predictions))\n",
    "    print(\"Confusion Matrix\")\n",
    "    train_cm = confusion_matrix(\n",
    "        trainY.argmax(axis=1), train_predictions.argmax(axis=1))\n",
    "    print(train_cm)\n",
    "\n",
    "    print(\"************ Testing Metrics ************\")\n",
    "\n",
    "#     print(\"Loss = \", test_score[0])\n",
    "    print(\"Accuracy = \", test_score[1])\n",
    "#     print(\"classification Report\")\n",
    "#     print(classification_report(testY, test_predictions))\n",
    "    print(\"Confusion Matrix\")\n",
    "    test_cm = confusion_matrix(\n",
    "        testY.argmax(axis=1), test_predictions.argmax(axis=1))\n",
    "    print(test_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the image to a fixed size, then flatten the image into\n",
    "# a list of raw pixel intensities\n",
    "\n",
    "def image_to_feature_vector(image, size=(32, 32)):\n",
    "    return cv2.resize(image, size).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
