{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and loading necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "\n",
    "from imutils import paths\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from keras import applications\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, precision_recall_fscore_support, average_precision_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset path\n",
    "\n",
    "path = 'data/cat_and_dog_1000'\n",
    "# path = 'data/cat_and_dog_1000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise required variables\n",
    "data = []\n",
    "labels = []\n",
    "features = []\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise required hyperparameters\n",
    "IMAGE_DIM = 48\n",
    "TEST_SPLIT = 0.20\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 3\n",
    "INIT_LR = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class information :  {'cat': 0, 'dog': 1}\n"
     ]
    }
   ],
   "source": [
    "# Extracting the class information from the given folder : Class name and corresponding number of files\n",
    "class_dir_paths = os.listdir(path)\n",
    "class_dict = {}\n",
    "idx = 0\n",
    "\n",
    "for class_dir_path in class_dir_paths:\n",
    "    if (os.path.isdir(os.path.join(path, class_dir_path))):\n",
    "        class_name = class_dir_path\n",
    "        class_dict[class_name] = idx\n",
    "        idx += 1\n",
    "\n",
    "print(\"Class information : \", class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the image paths and randomly shuffle them\n",
    "imagePaths = sorted(list(paths.list_images(path)))\n",
    "random.seed(RANDOM_STATE)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/cat_and_dog_1000/cat/cat.813.jpg'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagePaths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images readed,  2001\n",
      "Total number of labels extracted,  2001\n"
     ]
    }
   ],
   "source": [
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (IMAGE_DIM, IMAGE_DIM))\n",
    "    image = img_to_array(image)\n",
    "    feature = image_to_feature_vector(image)\n",
    "    data.append(image)\n",
    "    features.append(feature)\n",
    "\n",
    "    # extract the class label from the image path and update the\n",
    "    # labels list\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(class_dict[label])\n",
    "\n",
    "print(\"Total number of images readed, \", len(data))\n",
    "print(\"Total number of labels extracted, \", len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image in training set  1600 1600\n",
      "Number of image in tesing set  401 401\n"
     ]
    }
   ],
   "source": [
    "features = np.array(features, dtype=\"float\") / 255.0\n",
    "\n",
    "(ttrainX, ttestX, ttrainY, ttestY) = train_test_split(\n",
    "    features, labels, test_size=TEST_SPLIT, random_state=RANDOM_STATE)\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "ttrainY = to_categorical(ttrainY, num_classes=len(class_dict))\n",
    "ttestY = to_categorical(ttestY, num_classes=len(class_dict))\n",
    "\n",
    "print(\"Number of image in training set \", len(ttrainX), len(ttrainY))\n",
    "print(\"Number of image in tesing set \", len(ttestX), len(ttestY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the architecture of the network\n",
    "model = Sequential()\n",
    "model.add(Dense(768, input_dim=3072, activation=\"relu\"))\n",
    "model.add(Dense(384, activation=\"relu\"))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 768)               2360064   \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 384)               295296    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 2)                 770       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 2,656,130\n",
      "Trainable params: 2,656,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "sgd = SGD(lr=0.01)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Train on 1600 samples, validate on 401 samples\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 2s 993us/step - loss: 0.7351 - acc: 0.5225 - val_loss: 0.6828 - val_acc: 0.5586\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 1s 632us/step - loss: 0.6839 - acc: 0.5675 - val_loss: 0.6916 - val_acc: 0.5387\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 1s 666us/step - loss: 0.6727 - acc: 0.5881 - val_loss: 0.6756 - val_acc: 0.5611\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training network...\")\n",
    "nn_history = model.fit(\n",
    "    ttrainX,\n",
    "    ttrainY,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    validation_data=(ttestX, ttestY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 0s 90us/step\n",
      "401/401 [==============================] - 0s 111us/step\n",
      "************ Training Metrics ************\n",
      "Accuracy =  0.546875\n",
      "Confusion Matrix\n",
      "[[782   4]\n",
      " [721  93]]\n",
      "************ Testing Metrics ************\n",
      "Accuracy =  0.5610972573780953\n",
      "Confusion Matrix\n",
      "[[209   6]\n",
      " [170  16]]\n"
     ]
    }
   ],
   "source": [
    "print_score(model, ttrainX, ttrainY, ttestX, ttestY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_save_metrics(nn_history, 'nn_plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image in training set  1600 1600\n",
      "Number of image in tesing set  401 401\n"
     ]
    }
   ],
   "source": [
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=TEST_SPLIT, random_state=RANDOM_STATE)\n",
    "\n",
    "print(\"Number of image in training set \", len(trainX), len(trainY))\n",
    "print(\"Number of image in tesing set \", len(testX), len(testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels from integers to vectors\n",
    "trainY = to_categorical(trainY, num_classes=len(class_dict))\n",
    "testY = to_categorical(testY, num_classes=len(class_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_net(width, height, depth, classes):\n",
    "\n",
    "    finalAct = \"softmax\" if classes > 2 else \"sigmoid\"\n",
    "\n",
    "    # initialize the model\n",
    "    model = Sequential()\n",
    "    inputShape = (height, width, depth)\n",
    "\n",
    "    # if we are using \"channels first\", update the input shape\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        inputShape = (depth, height, width)\n",
    "\n",
    "    # first set of CONV => RELU => POOL layers\n",
    "    model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=inputShape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # second set of CONV => RELU => POOL layers\n",
    "    model.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # first (and only) set of FC => RELU layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    # softmax classifier\n",
    "    model.add(Dense(classes))\n",
    "    model.add(Activation(finalAct))\n",
    "\n",
    "    # return the constructed network architecture\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simple_net(IMAGE_DIM, IMAGE_DIM, 3, len(class_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the optimizer\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "\n",
    "# Complile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/3\n",
      "50/50 [==============================] - 9s 175ms/step - loss: 0.7445 - acc: 0.5109 - val_loss: 0.6913 - val_acc: 0.5112\n",
      "Epoch 2/3\n",
      "50/50 [==============================] - 8s 165ms/step - loss: 0.6897 - acc: 0.5406 - val_loss: 0.6795 - val_acc: 0.5411\n",
      "Epoch 3/3\n",
      "50/50 [==============================] - 8s 165ms/step - loss: 0.6794 - acc: 0.5741 - val_loss: 0.6947 - val_acc: 0.4838\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training network...\")\n",
    "H = model.fit_generator(\n",
    "    aug.flow(trainX, trainY, batch_size=BATCH_SIZE),\n",
    "    validation_data=(testX, testY),\n",
    "    steps_per_epoch=len(trainX) // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 2s 1ms/step\n",
      "401/401 [==============================] - 1s 1ms/step\n",
      "************ Training Metrics ************\n",
      "Accuracy =  0.5278125\n",
      "Confusion Matrix\n",
      "[[ 41 745]\n",
      " [ 10 804]]\n",
      "************ Testing Metrics ************\n",
      "Accuracy =  0.4837905242853331\n",
      "Confusion Matrix\n",
      "[[ 12 203]\n",
      " [  3 183]]\n"
     ]
    }
   ],
   "source": [
    "print_score(model,trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('keras_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the saved model and do prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading network...\n"
     ]
    }
   ],
   "source": [
    "# load the image\n",
    "image = cv2.imread('data/cat_and_dog_1000/cat/cat.813.jpg')\n",
    "orig = image.copy()\n",
    "\n",
    "# pre-process the image for classification\n",
    "image = cv2.resize(image, (IMAGE_DIM, IMAGE_DIM))\n",
    "image = image.astype(\"float\") / 255.0\n",
    "image = img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)\n",
    "\n",
    "# load the trained convolutional neural network\n",
    "print(\"[INFO] loading network...\")\n",
    "model = load_model('keras_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cat, dog) = model.predict(image)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4179721, 0.5898914)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One with the highest value is our prediction\n",
    "(cat, dog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(IMAGE_DIM, IMAGE_DIM, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 48, 48, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze all the layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building model based on Function API\n",
    "X = base_model.output\n",
    "X = Flatten()(X)  \n",
    "\n",
    "#Adding last FC layers based on hyperparams given\n",
    "\n",
    "X = Dense(128, activation='relu')(X)\n",
    "X = Dense(128, activation='relu')(X)\n",
    "\n",
    "# for layer_param in hyperparameters['top_layers']:\n",
    "# \tX = self.layers[layer_param[0]](layer_param[1], activation=layer_param[2])(X)\n",
    "\n",
    "#Adding dropout\n",
    "X = Dropout(0.5)(X)\n",
    "\n",
    "#Adding the last layer for prediction\n",
    "predictions = Dense(2, activation='sigmoid')(X)\n",
    "\n",
    "#creating the final model\n",
    "model = Model(base_model.input, predictions)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 48, 48, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 14,797,122\n",
      "Trainable params: 82,434\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/3\n",
      "50/50 [==============================] - 25s 492ms/step - loss: 0.6457 - acc: 0.6200 - val_loss: 0.5857 - val_acc: 0.6746\n",
      "Epoch 2/3\n",
      "50/50 [==============================] - 25s 496ms/step - loss: 0.5952 - acc: 0.6797 - val_loss: 0.5640 - val_acc: 0.7057\n",
      "Epoch 3/3\n",
      "50/50 [==============================] - 25s 492ms/step - loss: 0.5774 - acc: 0.6972 - val_loss: 0.5521 - val_acc: 0.7170\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training network...\")\n",
    "H = model.fit_generator(\n",
    "    aug.flow(trainX, trainY, batch_size=BATCH_SIZE),\n",
    "    validation_data=(testX, testY),\n",
    "    steps_per_epoch=len(trainX) // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 19s 12ms/step\n",
      "401/401 [==============================] - 5s 12ms/step\n",
      "************ Training Metrics ************\n",
      "Accuracy =  0.7646875\n",
      "Confusion Matrix\n",
      "[[581 205]\n",
      " [169 645]]\n",
      "************ Testing Metrics ************\n",
      "Accuracy =  0.7169576050931973\n",
      "Confusion Matrix\n",
      "[[142  73]\n",
      " [ 40 146]]\n"
     ]
    }
   ],
   "source": [
    "print_score(model,trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze only the last few layers\n",
    "N_LAYERS_TO_FREEZE = 15\n",
    "\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in model.layers[15:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "# Unfreeze all the layers\n",
    "# for layer in model.layers:\n",
    "#     layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Finetuning the network...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Finetuning the network...\")\n",
    "model.compile(\n",
    "    optimizer=SGD(lr=0.001, momentum=0.9),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "50/50 [==============================] - 45s 891ms/step - loss: 0.5629 - acc: 0.7191 - val_loss: 0.5045 - val_acc: 0.7481\n",
      "Epoch 2/3\n",
      "50/50 [==============================] - 43s 869ms/step - loss: 0.5050 - acc: 0.7534 - val_loss: 0.5376 - val_acc: 0.7357\n",
      "Epoch 3/3\n",
      "50/50 [==============================] - 45s 892ms/step - loss: 0.4884 - acc: 0.7706 - val_loss: 0.5564 - val_acc: 0.7170\n"
     ]
    }
   ],
   "source": [
    "H_tune = model.fit_generator(\n",
    "    aug.flow(trainX, trainY, batch_size=BATCH_SIZE),\n",
    "    validation_data=(testX, testY),\n",
    "    steps_per_epoch=len(trainX) // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 18s 11ms/step\n",
      "401/401 [==============================] - 5s 12ms/step\n",
      "************ Training Metrics ************\n",
      "Accuracy =  0.79625\n",
      "Confusion Matrix\n",
      "[[507 279]\n",
      " [ 42 772]]\n",
      "************ Testing Metrics ************\n",
      "Accuracy =  0.7169576061336774\n",
      "Confusion Matrix\n",
      "[[118  97]\n",
      " [ 15 171]]\n"
     ]
    }
   ],
   "source": [
    "print_score(model,trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_save_metrics(model_history):\n",
    "\n",
    "    # plot the training loss and accuracy\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    N = EPOCHS\n",
    "    plt.plot(\n",
    "        np.arange(0, N), model_history.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(\n",
    "        np.arange(0, N), model_history.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(np.arange(0, N), model_history.history[\"acc\"], label=\"train_acc\")\n",
    "    plt.plot(\n",
    "        np.arange(0, N), model_history.history[\"val_acc\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(model, trainX, trainY, testX, testY):\n",
    "\n",
    "    train_score = model.evaluate(trainX, trainY)\n",
    "    train_predictions = model.predict(trainX)\n",
    "    train_predictions = np.round(train_predictions)\n",
    "\n",
    "    test_score = model.evaluate(testX, testY)\n",
    "    test_predictions = model.predict(testX)\n",
    "    test_predictions = np.round(test_predictions)\n",
    "\n",
    "    print(\"************ Training Metrics ************\")\n",
    "\n",
    "#     print(\"Loss = \", train_score[0])\n",
    "    print(\"Accuracy = \", train_score[1])\n",
    "#     print(\"classification Report\")\n",
    "#     print(classification_report(trainY, train_predictions))\n",
    "    print(\"Confusion Matrix\")\n",
    "    train_cm = confusion_matrix(\n",
    "        trainY.argmax(axis=1), train_predictions.argmax(axis=1))\n",
    "    print(train_cm)\n",
    "\n",
    "    print(\"************ Testing Metrics ************\")\n",
    "\n",
    "#     print(\"Loss = \", test_score[0])\n",
    "    print(\"Accuracy = \", test_score[1])\n",
    "#     print(\"classification Report\")\n",
    "#     print(classification_report(testY, test_predictions))\n",
    "    print(\"Confusion Matrix\")\n",
    "    test_cm = confusion_matrix(\n",
    "        testY.argmax(axis=1), test_predictions.argmax(axis=1))\n",
    "    print(test_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the image to a fixed size, then flatten the image into\n",
    "# a list of raw pixel intensities\n",
    "\n",
    "def image_to_feature_vector(image, size=(32, 32)):\n",
    "    return cv2.resize(image, size).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
